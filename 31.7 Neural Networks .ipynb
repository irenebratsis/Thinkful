{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MOMA dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = pd.read_csv('https://media.githubusercontent.com/media/MuseumofModernArt/collection/master/Artists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ConstituentID', 'DisplayName', 'ArtistBio', 'Nationality', 'Gender',\n",
       "       'BeginDate', 'EndDate', 'Wiki QID', 'ULAN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Columns.\n",
    "collection = collection[['ConstituentID', 'DisplayName', 'ArtistBio', 'Nationality', 'Gender',\n",
    "       'BeginDate', 'EndDate', 'Wiki QID', 'ULAN']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Drop missing data.\n",
    "collection = collection.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConstituentID</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>ArtistBio</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BeginDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Wiki QID</th>\n",
       "      <th>ULAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Charles Arnoldi</td>\n",
       "      <td>American, born 1946</td>\n",
       "      <td>American</td>\n",
       "      <td>Male</td>\n",
       "      <td>1946</td>\n",
       "      <td>0</td>\n",
       "      <td>Q1063584</td>\n",
       "      <td>500027998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>David Aronson</td>\n",
       "      <td>American, born Lithuania 1923</td>\n",
       "      <td>American</td>\n",
       "      <td>Male</td>\n",
       "      <td>1923</td>\n",
       "      <td>0</td>\n",
       "      <td>Q5230870</td>\n",
       "      <td>500003363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Irene Aronson</td>\n",
       "      <td>American, born Germany 1918</td>\n",
       "      <td>American</td>\n",
       "      <td>Female</td>\n",
       "      <td>1918</td>\n",
       "      <td>0</td>\n",
       "      <td>Q19748568</td>\n",
       "      <td>500042413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>Jean (Hans) Arp</td>\n",
       "      <td>French, born Germany (Alsace). 1886–1966</td>\n",
       "      <td>French</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886</td>\n",
       "      <td>1966</td>\n",
       "      <td>Q153739</td>\n",
       "      <td>500031000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19</td>\n",
       "      <td>Richard Artschwager</td>\n",
       "      <td>American, 1923–2013</td>\n",
       "      <td>American</td>\n",
       "      <td>Male</td>\n",
       "      <td>1923</td>\n",
       "      <td>2013</td>\n",
       "      <td>Q568262</td>\n",
       "      <td>500114981.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ConstituentID          DisplayName  \\\n",
       "3               4      Charles Arnoldi   \n",
       "7               9        David Aronson   \n",
       "8              10        Irene Aronson   \n",
       "9              11      Jean (Hans) Arp   \n",
       "15             19  Richard Artschwager   \n",
       "\n",
       "                                   ArtistBio Nationality  Gender  BeginDate  \\\n",
       "3                        American, born 1946    American    Male       1946   \n",
       "7              American, born Lithuania 1923    American    Male       1923   \n",
       "8                American, born Germany 1918    American  Female       1918   \n",
       "9   French, born Germany (Alsace). 1886–1966      French    Male       1886   \n",
       "15                       American, 1923–2013    American    Male       1923   \n",
       "\n",
       "    EndDate   Wiki QID         ULAN  \n",
       "3         0   Q1063584  500027998.0  \n",
       "7         0   Q5230870  500003363.0  \n",
       "8         0  Q19748568  500042413.0  \n",
       "9      1966    Q153739  500031000.0  \n",
       "15     2013    Q568262  500114981.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConstituentID      int64\n",
       "DisplayName       object\n",
       "ArtistBio         object\n",
       "Nationality       object\n",
       "Gender            object\n",
       "BeginDate          int64\n",
       "EndDate            int64\n",
       "Wiki QID          object\n",
       "ULAN             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data types.\n",
    "collection.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Final column drops and NA drop.\n",
    "X = collection.drop(['Wiki QID', 'DisplayName', 'ArtistBio', 'Nationality', 'Gender'], 1)\n",
    "\n",
    "# Create dummies separately.\n",
    "gender = pd.get_dummies(collection.Gender)\n",
    "\n",
    "\n",
    "# Concat with other variables, but artists slows this wayyyyy down so we'll keep it out for now\n",
    "X = pd.get_dummies(X, sparse=True)\n",
    "X = pd.concat([X, gender], axis=1)\n",
    "\n",
    "Y = collection.Nationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=0.9,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(2000,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alright! We've done our prep, let's build the model.\n",
    "# Neural networks are hugely computationally intensive.\n",
    "# This may take several minutes to run.\n",
    "\n",
    "# Import the model.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Establish and fit the model, with a single, 1000 perceptron layer.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(2000,))\n",
    "mlp.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "American         0.421016\n",
       "French           0.097425\n",
       "British          0.096729\n",
       "German           0.093946\n",
       "Italian          0.043145\n",
       "Japanese         0.026444\n",
       "Swiss            0.023660\n",
       "Dutch            0.018441\n",
       "Austrian         0.017745\n",
       "Russian          0.013918\n",
       "Canadian         0.012874\n",
       "Mexican          0.012526\n",
       "Belgian          0.011830\n",
       "Spanish          0.011482\n",
       "Brazilian        0.009743\n",
       "Polish           0.008699\n",
       "Argentine        0.006959\n",
       "Swedish          0.005567\n",
       "Czech            0.005219\n",
       "Danish           0.005219\n",
       "Israeli          0.004523\n",
       "Australian       0.004175\n",
       "Finnish          0.003827\n",
       "Venezuelan       0.002784\n",
       "South African    0.002784\n",
       "Hungarian        0.002784\n",
       "Cuban            0.002436\n",
       "Chilean          0.002436\n",
       "Chinese          0.002436\n",
       "Colombian        0.002088\n",
       "                   ...   \n",
       "Guatemalan       0.000696\n",
       "Turkish          0.000696\n",
       "Scottish         0.000696\n",
       "Iranian          0.000696\n",
       "Croatian         0.000696\n",
       "Slovak           0.000696\n",
       "Korean           0.000696\n",
       "Slovenian        0.000696\n",
       "Bolivian         0.000348\n",
       "Latvian          0.000348\n",
       "Ecuadorian       0.000348\n",
       "Malian           0.000348\n",
       "Lebanese         0.000348\n",
       "Sudanese         0.000348\n",
       "Georgian         0.000348\n",
       "Congolese        0.000348\n",
       "Luxembourgish    0.000348\n",
       "Taiwanese        0.000348\n",
       "Ghanaian         0.000348\n",
       "Albanian         0.000348\n",
       "Namibian         0.000348\n",
       "Bahamian         0.000348\n",
       "Thai             0.000348\n",
       "Portuguese       0.000348\n",
       "Pakistani        0.000348\n",
       "Moroccan         0.000348\n",
       "Egyptian         0.000348\n",
       "Bosnian          0.000348\n",
       "Kenyan           0.000348\n",
       "Bulgarian        0.000348\n",
       "Name: Nationality, Length: 72, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "American         0.421016\n",
       "French           0.097425\n",
       "British          0.096729\n",
       "German           0.093946\n",
       "Italian          0.043145\n",
       "Japanese         0.026444\n",
       "Swiss            0.023660\n",
       "Dutch            0.018441\n",
       "Austrian         0.017745\n",
       "Russian          0.013918\n",
       "Canadian         0.012874\n",
       "Mexican          0.012526\n",
       "Belgian          0.011830\n",
       "Spanish          0.011482\n",
       "Brazilian        0.009743\n",
       "Polish           0.008699\n",
       "Argentine        0.006959\n",
       "Swedish          0.005567\n",
       "Czech            0.005219\n",
       "Danish           0.005219\n",
       "Israeli          0.004523\n",
       "Australian       0.004175\n",
       "Finnish          0.003827\n",
       "Venezuelan       0.002784\n",
       "South African    0.002784\n",
       "Hungarian        0.002784\n",
       "Cuban            0.002436\n",
       "Chilean          0.002436\n",
       "Chinese          0.002436\n",
       "Colombian        0.002088\n",
       "                   ...   \n",
       "Guatemalan       0.000696\n",
       "Turkish          0.000696\n",
       "Scottish         0.000696\n",
       "Iranian          0.000696\n",
       "Croatian         0.000696\n",
       "Slovak           0.000696\n",
       "Korean           0.000696\n",
       "Slovenian        0.000696\n",
       "Bolivian         0.000348\n",
       "Latvian          0.000348\n",
       "Ecuadorian       0.000348\n",
       "Malian           0.000348\n",
       "Lebanese         0.000348\n",
       "Sudanese         0.000348\n",
       "Georgian         0.000348\n",
       "Congolese        0.000348\n",
       "Luxembourgish    0.000348\n",
       "Taiwanese        0.000348\n",
       "Ghanaian         0.000348\n",
       "Albanian         0.000348\n",
       "Namibian         0.000348\n",
       "Bahamian         0.000348\n",
       "Thai             0.000348\n",
       "Portuguese       0.000348\n",
       "Pakistani        0.000348\n",
       "Moroccan         0.000348\n",
       "Egyptian         0.000348\n",
       "Bosnian          0.000348\n",
       "Kenyan           0.000348\n",
       "Bulgarian        0.000348\n",
       "Name: Nationality, Length: 72, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.39477977, 0.41367521, 0.0122807 , 0.10071942, 0.44      ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(mlp, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012526096033402923"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok so we got an MLP score of .0125, now let's comparing with Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Slovenian'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-131749007386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mrandomforest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mrandomforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mrandomforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDOUBLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mascontiguousarray\u001b[0;34m(a, dtype)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \"\"\"\n\u001b[0;32m--> 590\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Slovenian'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import ensemble\n",
    "# Final column drops and NA drop.\n",
    "X = collection.drop(['Wiki QID', 'DisplayName', 'ArtistBio', 'Nationality', 'Gender'], 1)\n",
    "\n",
    "# Create dummies separately.\n",
    "gender = pd.get_dummies(collection.Gender)\n",
    "\n",
    "\n",
    "# Concat with other variables, but artists slows this wayyyyy down so we'll keep it out for now\n",
    "X = pd.get_dummies(X, sparse=True)\n",
    "X = pd.concat([X, gender], axis=1)\n",
    "\n",
    "Y = collection.Nationality\n",
    "\n",
    "randomforest = RandomForestRegressor()\n",
    "randomforest.fit(X_train, Y_train)\n",
    "randomforest.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
